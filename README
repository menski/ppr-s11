Praktikum Paralleles Rechnen

Aufgabenstellung: Aufrufen aller Wikipedia Artikel, damit alle Thumbnails
generiert werden.

Pakete:
 - httpasync:
    - http      : Enthält die wichtigesten Grundklassen, wie HTTPAsyncClient
                  einen HTTP/1.1 Client der persistente Verbindungen unterstützt.
                  Oder HTTPCrawler der HTTPAsyncClient Instanzen nutzt um, in
                  einem eigenen Thread, asynchrone HTTP Requests zu senden.
    - wiki      : Enthält die spezielen Wikipedia Instanzen von HTTPAsyncClient
                  und HTTPCrawler.
    - tracei    : Enhält Klassen und Funktionen zum verarbeiten von Traces.

Dateien:
 - crawler.py   : Enthält eine main()-Routine, welche mehere Crawler konfiguriert
                  und aufruft. Und so mit multithreading nutzt.

 - fetcher.py   : Enthält einen Datenbank fetcher für die Wikipedia MySQL
                  Datenbank um alle Artikel URL's zu generieren.

 - analyze-trace.py : Enthält einen TraceAnalyzer für die Wikipedia Traces von
                      wikibench.eu. Es wird eine <tracefile>.stats Datei angelegt,
                      welche die Statistik des Trace enthälts. Wird die plot-Option
                      aktiviert, wird zusätlich noch eine <tracefile>.log und
                      <tracefile>.eps Datei angelegt, welche das gnuplot Log und
                      die gnuplot Ausgabe enthalten.

 - filter-trace.py  : Enthält einen TraceFilter für Wikipedia Traces von wikibench.eu.
                      Es wird ein gefiltertes Tracefile angelegt unter dem Name
                      <tracefile>.<start>-<end> und optional analysiert.

Aufruf:
    Siehe 'crawler.py -h' füre weitere Informationen.
    Siehe 'fetcher.py -h' füre weitere Informationen.
    Siehe 'analzye-trace.py -h' füre weitere Informationen.
    Siehe 'filter-trace.py -h' füre weitere Informationen.
